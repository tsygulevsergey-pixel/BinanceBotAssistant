"""
Fast Catchup Loader - –ë—ã—Å—Ç—Ä–∞—è –¥–æ–≥—Ä—É–∑–∫–∞ gaps –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ –±–æ—Ç–∞
"""
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import pytz
from src.database.models import Candle

logger = logging.getLogger('trading_bot')


class FastCatchupLoader:
    """–£–º–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –±—ã—Å—Ç—Ä–æ–π –¥–æ–≥—Ä—É–∑–∫–∏ gaps –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ"""
    
    def __init__(self, data_loader, db):
        """
        Args:
            data_loader: DataLoader instance
            db: Database session
        """
        self.data_loader = data_loader
        self.db = db
        self.timeframes = ['15m', '1h', '4h', '1d']
        
    def analyze_restart_state(self, symbols: List[str], current_time: datetime) -> Tuple[Dict, List[str]]:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ë–î –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –∑–∞–≥—Ä—É–∑–∫–∏
        
        Args:
            symbols: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            current_time: –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è UTC
            
        Returns:
            (existing_gaps, new_symbols) - —Å–∏–º–≤–æ–ª—ã —Å gaps –∏ –Ω–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
        """
        existing_gaps = {}
        new_symbols = []
        
        logger.info("üìä Analyzing restart state...")
        
        for symbol in symbols:
            gaps = self._calculate_symbol_gaps(symbol, current_time)
            
            if gaps:
                # –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –ë–î, –Ω–æ –µ—Å—Ç—å gaps
                existing_gaps[symbol] = gaps
            elif not self._has_any_data(symbol):
                # –°–æ–≤—Å–µ–º –Ω–æ–≤—ã–π —Å–∏–º–≤–æ–ª
                new_symbols.append(symbol)
        
        total_gap_requests = sum(len(gaps) for gaps in existing_gaps.values())
        
        logger.info(
            f"üìä Restart analysis:\n"
            f"  ‚úÖ Existing symbols with gaps: {len(existing_gaps)} ({total_gap_requests} total requests)\n"
            f"  üÜï New symbols: {len(new_symbols)}\n"
            f"  üìà Total symbols: {len(symbols)}"
        )
        
        return existing_gaps, new_symbols
    
    def _calculate_symbol_gaps(self, symbol: str, current_time: datetime) -> Dict[str, Dict]:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å gaps –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        
        Returns:
            Dict[timeframe, {'start': datetime, 'end': datetime, 'candles_needed': int}]
        """
        gaps = {}
        
        for tf in self.timeframes:
            last_candle_time = self._get_last_candle_time(symbol, tf)
            
            if last_candle_time:
                # –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ - –ø—Ä–æ–≤–µ—Ä—è–µ–º gap
                expected_next = self._get_next_candle_time(last_candle_time, tf)
                
                if expected_next < current_time:
                    # –ï—Å—Ç—å gap
                    candles_needed = self._estimate_candles_needed(expected_next, current_time, tf)
                    
                    gaps[tf] = {
                        'start': expected_next,
                        'end': current_time,
                        'candles_needed': candles_needed,
                        'last_candle': last_candle_time
                    }
        
        return gaps
    
    def _get_last_candle_time(self, symbol: str, timeframe: str) -> Optional[datetime]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–≤–µ—á–∏ –∏–∑ –ë–î"""
        session = self.db.get_session()
        try:
            latest_candle = session.query(Candle).filter(
                Candle.symbol == symbol,
                Candle.timeframe == timeframe
            ).order_by(Candle.open_time.desc()).first()
            
            if latest_candle and latest_candle.open_time:
                # Ensure timezone-aware datetime
                last_time = latest_candle.open_time
                if last_time.tzinfo is None:
                    last_time = pytz.UTC.localize(last_time)
                return last_time
            return None
        finally:
            session.close()
    
    def _has_any_data(self, symbol: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ —Ö–æ—Ç—å –∫–∞–∫–∏–µ-—Ç–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
        for tf in self.timeframes:
            if self._get_last_candle_time(symbol, tf):
                return True
        return False
    
    def _get_next_candle_time(self, last_time: datetime, timeframe: str) -> datetime:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Ä–µ–º—è —Å–ª–µ–¥—É—é—â–µ–π —Å–≤–µ—á–∏"""
        intervals = {
            '15m': timedelta(minutes=15),
            '1h': timedelta(hours=1),
            '4h': timedelta(hours=4),
            '1d': timedelta(days=1)
        }
        return last_time + intervals[timeframe]
    
    def _estimate_candles_needed(self, start: datetime, end: datetime, timeframe: str) -> int:
        """–û—Ü–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–µ—á–µ–π –≤ gap"""
        delta = end - start
        
        intervals = {
            '15m': 15,
            '1h': 60,
            '4h': 240,
            '1d': 1440
        }
        
        minutes = delta.total_seconds() / 60
        candles = int(minutes / intervals[timeframe]) + 1
        return candles
    
    async def burst_catchup(self, existing_gaps: Dict[str, Dict], 
                           max_parallel: Optional[int] = None) -> Tuple[int, int]:
        """
        –ë—ã—Å—Ç—Ä–∞—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –¥–æ–≥—Ä—É–∑–∫–∞ gaps
        
        Args:
            existing_gaps: Dict[symbol, Dict[tf, gap_info]]
            max_parallel: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ (auto –µ—Å–ª–∏ None)
            
        Returns:
            (success_count, failed_count)
        """
        if not existing_gaps:
            return 0, 0
        
        total_requests = sum(len(gaps) for gaps in existing_gaps.values())
        
        # –£–º–Ω—ã–π —Ä–∞—Å—á—ë—Ç parallelism –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—ä—ë–º–∞
        if max_parallel is None:
            max_parallel = self._calculate_optimal_parallelism(total_requests)
        
        logger.info(
            f"‚ö° Starting BURST CATCHUP mode:\n"
            f"  üì¶ Symbols to update: {len(existing_gaps)}\n"
            f"  üìä Total requests: {total_requests}\n"
            f"  üîÑ Parallel workers: {max_parallel}\n"
            f"  ‚è±Ô∏è  Estimated time: {self._estimate_burst_time(total_requests, max_parallel)} seconds"
        )
        
        semaphore = asyncio.Semaphore(max_parallel)
        success_count = 0
        failed_count = 0
        
        async def load_symbol_gaps(symbol: str, gaps: Dict):
            nonlocal success_count, failed_count
            
            async with semaphore:
                try:
                    for tf, gap_info in gaps.items():
                        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å rate limit –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º (90% –ø–æ—Ä–æ–≥)
                        if hasattr(self.data_loader, 'client') and hasattr(self.data_loader.client, 'rate_limiter'):
                            usage = self.data_loader.client.rate_limiter.get_current_usage()
                            if usage.get('is_near_limit', False):
                                logger.info(
                                    f"‚è∏Ô∏è Pausing burst catchup: rate limit at "
                                    f"{usage['percent_of_safe']:.1f}% of safe threshold"
                                )
                                # –ü–æ–¥–æ–∂–¥–∞—Ç—å —Å–±—Ä–æ—Å–∞ –ª–∏–º–∏—Ç–∞
                                await self.data_loader.client.rate_limiter.wait_if_near_limit(weight=5)
                        
                        # –ó–∞–≥—Ä—É–∑–∏—Ç—å gap
                        df = await self.data_loader.download_historical_klines(
                            symbol, tf,
                            start_date=gap_info['start'],
                            end_date=gap_info['end']
                        )
                        
                        if df is not None and len(df) > 0:
                            # _save_candles —É–∂–µ async, –Ω–µ –Ω—É–∂–µ–Ω to_thread
                            logger.debug(f"Loaded {len(df)} candles for {symbol} {tf}")
                            
                            logger.debug(
                                f"  ‚úÖ {symbol} {tf}: +{len(df)} candles "
                                f"({gap_info['start'].strftime('%H:%M')} ‚Üí {gap_info['end'].strftime('%H:%M')})"
                            )
                        
                        # –ú–∏–∫—Ä–æ-–ø–∞—É–∑–∞ –¥–ª—è rate limit
                        await asyncio.sleep(0.05)
                    
                    success_count += 1
                    
                except Exception as e:
                    logger.error(f"  ‚ùå {symbol} catchup failed: {e}")
                    failed_count += 1
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö gaps –° –ë–ê–¢–ß–ò–†–û–í–ê–ù–ò–ï–ú –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ rate limiter
        start_time = datetime.now()
        
        # –†–∞–∑–±–∏—Ç—å —Å–∏–º–≤–æ–ª—ã –Ω–∞ –±–∞—Ç—á–∏ –ø–æ 20 —Å–∏–º–≤–æ–ª–æ–≤ (–±–µ–∑–æ–ø–∞—Å–Ω–µ–µ –¥–ª—è rate limiter)
        BATCH_SIZE = 20
        BATCH_PAUSE = 0.5  # –ü–∞—É–∑–∞ 0.5 —Å–µ–∫ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limit spikes
        
        symbol_items = list(existing_gaps.items())
        total_batches = (len(symbol_items) + BATCH_SIZE - 1) // BATCH_SIZE
        
        logger.info(
            f"üì¶ Splitting {len(symbol_items)} symbols into {total_batches} batches "
            f"(batch size: {BATCH_SIZE}, pause: {BATCH_PAUSE}s)"
        )
        
        for batch_num in range(total_batches):
            batch_start = batch_num * BATCH_SIZE
            batch_end = min(batch_start + BATCH_SIZE, len(symbol_items))
            batch = symbol_items[batch_start:batch_end]
            
            logger.info(
                f"üìä Processing batch {batch_num+1}/{total_batches} "
                f"({len(batch)} symbols: {batch[0][0]} ... {batch[-1][0]})"
            )
            
            tasks = [load_symbol_gaps(symbol, gaps) for symbol, gaps in batch]
            await asyncio.gather(*tasks)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å rate usage –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞
            if hasattr(self.data_loader, 'client') and hasattr(self.data_loader.client, 'rate_limiter'):
                usage = self.data_loader.client.rate_limiter.get_current_usage()
                current_percent = usage.get('percent_of_safe', 0)
                
                # –ï—Å–ª–∏ rate > 50% –æ—Ç safe threshold - —É–≤–µ–ª–∏—á–∏—Ç—å –ø–∞—É–∑—É
                if current_percent > 50:
                    extra_pause = 2.0  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞ 2 —Å–µ–∫—É–Ω–¥—ã
                    logger.info(
                        f"‚è∏Ô∏è Rate usage {current_percent:.1f}% > 50%, adding {extra_pause}s pause"
                    )
                    await asyncio.sleep(extra_pause)
            
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏ (–∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
            if batch_num < total_batches - 1:
                logger.debug(f"‚è∏Ô∏è Batch pause {BATCH_PAUSE}s before next batch")
                await asyncio.sleep(BATCH_PAUSE)
        
        elapsed = (datetime.now() - start_time).total_seconds()
        
        logger.info(
            f"‚ö° BURST CATCHUP COMPLETE:\n"
            f"  ‚úÖ Success: {success_count} symbols\n"
            f"  ‚ùå Failed: {failed_count} symbols\n"
            f"  ‚è±Ô∏è  Time: {elapsed:.1f}s (avg {elapsed/len(existing_gaps):.2f}s per symbol)\n"
            f"  üöÄ Speed: {total_requests/elapsed:.1f} requests/sec"
        )
        
        return success_count, failed_count
    
    def _calculate_optimal_parallelism(self, total_requests: int) -> int:
        """
        –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫
        
        Args:
            total_requests: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤
            
        Returns:
            –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö workers
        """
        # Rate limit Binance: 1200 weight/min
        # Gap request weight: ~5
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ª–∏–º–∏—Ç: 800 weight/min (–∑–∞–ø–∞—Å)
        
        if total_requests < 30:
            # –ú–∞–ª–æ –∑–∞–ø—Ä–æ—Å–æ–≤ - –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
            return 12
        elif total_requests < 100:
            # –°—Ä–µ–¥–Ω–µ - –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–æ
            return 8
        elif total_requests < 300:
            # –ú–Ω–æ–≥–æ - –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ
            return 6
        else:
            # –û—á–µ–Ω—å –º–Ω–æ–≥–æ - –æ—á–µ–Ω—å –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω–æ
            return 4
    
    def _estimate_burst_time(self, total_requests: int, parallel: int) -> int:
        """–û—Ü–µ–Ω–∏—Ç—å –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è burst catchup –≤ —Å–µ–∫—É–Ω–¥–∞—Ö"""
        # –°—Ä–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å: ~0.3 —Å–µ–∫
        avg_request_time = 0.3
        
        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è / –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º + –Ω–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã
        sequential_time = total_requests * avg_request_time
        parallel_time = sequential_time / parallel
        overhead = 2  # –ù–∞–∫–ª–∞–¥–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã
        
        return int(parallel_time + overhead)
    
    def get_catchup_stats(self, existing_gaps: Dict) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ gaps –¥–ª—è –æ—Ç—á—ë—Ç–∞
        
        Returns:
            Dict —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        if not existing_gaps:
            return {
                'total_symbols': 0,
                'total_gaps': 0,
                'total_candles': 0,
                'by_timeframe': {}
            }
        
        stats = {
            'total_symbols': len(existing_gaps),
            'total_gaps': 0,
            'total_candles': 0,
            'by_timeframe': {tf: {'gaps': 0, 'candles': 0} for tf in self.timeframes}
        }
        
        for gaps in existing_gaps.values():
            for tf, gap_info in gaps.items():
                stats['total_gaps'] += 1
                stats['total_candles'] += gap_info['candles_needed']
                stats['by_timeframe'][tf]['gaps'] += 1
                stats['by_timeframe'][tf]['candles'] += gap_info['candles_needed']
        
        return stats
